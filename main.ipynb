{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26e07d9d",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b517957",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5953ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB ready\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, PageBreak\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.platypus import TableStyle\n",
    "from reportlab.lib import styles\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# Connexion\n",
    "con = duckdb.connect(\"football.duckdb\")\n",
    "\n",
    "# Sécurité mémoire\n",
    "con.execute(\"PRAGMA threads=4;\")\n",
    "con.execute(\"PRAGMA memory_limit='8GB';\")\n",
    "\n",
    "print(\"DuckDB ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61bb99",
   "metadata": {},
   "source": [
    "## Clean\n",
    "### Jointure Nom des joeurs et sensor_id en fonction des sessions_date\n",
    "Etant donnée que certain joueurs échanger de sensor, nous devons assigner tous les jouerus au bon sensor à la bonne date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630d59b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      n_rows  n_players  n_sessions  n_sensors\n",
      "0  166541023         42         258         29\n",
      "  session_type  n_sessions\n",
      "0         game          74\n",
      "1     practice         187\n"
     ]
    }
   ],
   "source": [
    "# Create a SQL view from the tracking table with relevant columns\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW tracking_v1 AS\n",
    "SELECT\n",
    "    session_type,\n",
    "    session_date,\n",
    "    player_id AS sensor_id,  -- Rename player_id to sensor_id to match sensor mapping\n",
    "    time_utc,\n",
    "    x_pos,\n",
    "    y_pos,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    speed_kmh\n",
    "FROM tracking\n",
    "\"\"\")\n",
    "\n",
    "# Load CSV mapping file and clean/format data\n",
    "df_map = (\n",
    "    pd.read_csv(\"data/summary.csv\", sep=\",\")\n",
    "    .assign(\n",
    "        session_date=lambda x: pd.to_datetime(\n",
    "            x[\"date\"],\n",
    "            format=\"%Y-%m-%d %H:%M:%S\",\n",
    "            errors=\"raise\"   # Convert to date and raise error if format is incorrect\n",
    "        ).dt.date\n",
    "    )\n",
    "    .rename(columns={\n",
    "        \"Sensor\": \"sensor_id\",  # Standardize column names\n",
    "        \"last_name\": \"player_id\"\n",
    "    })\n",
    "    [[\"session_date\", \"sensor_id\", \"player_id\"]]  # Keep only relevant columns\n",
    "    .drop_duplicates()  # Remove duplicate rows\n",
    ")\n",
    "\n",
    "# Register the DataFrame as a temporary table for SQL queries\n",
    "con.register(\"sensor_player_map\", df_map)\n",
    "\n",
    "# Create a SQL view from the temporary mapping table\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW mapping_v AS\n",
    "SELECT * FROM sensor_player_map\n",
    "\"\"\")\n",
    "\n",
    "# Join tracking data with sensor->player mapping\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW tracking_v2 AS\n",
    "SELECT\n",
    "    t.*,\n",
    "    m.player_id\n",
    "FROM tracking_v1 t\n",
    "LEFT JOIN mapping_v m\n",
    "ON t.sensor_id = m.sensor_id\n",
    "AND t.session_date = m.session_date\n",
    "\"\"\")\n",
    "\n",
    "# Identify sensors that could not be mapped to a player\n",
    "unmapped = con.execute(\"\"\"\n",
    "SELECT\n",
    "    session_date,\n",
    "    sensor_id,\n",
    "    COUNT(*) AS n_rows\n",
    "FROM tracking_v2\n",
    "WHERE player_id IS NULL\n",
    "GROUP BY session_date, sensor_id\n",
    "ORDER BY n_rows DESC\n",
    "\"\"\").df()\n",
    "\n",
    "# Create the final table containing only mapped rows\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE tracking_player AS\n",
    "SELECT *\n",
    "FROM tracking_v2\n",
    "WHERE player_id IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "# Summary statistics: total rows, unique players, sessions, and sensors\n",
    "summary = con.execute(\"\"\"\n",
    "SELECT\n",
    "    COUNT(*) AS n_rows,\n",
    "    COUNT(DISTINCT player_id) AS n_players,\n",
    "    COUNT(DISTINCT session_date) AS n_sessions,\n",
    "    COUNT(DISTINCT sensor_id) AS n_sensors\n",
    "FROM tracking_player\n",
    "\"\"\").df()\n",
    "\n",
    "# Summary by session type: number of unique sessions per type\n",
    "summary2 = con.execute(\"\"\"\n",
    "SELECT\n",
    "    session_type,\n",
    "    COUNT(DISTINCT session_date) AS n_sessions\n",
    "FROM tracking_player\n",
    "GROUP BY session_type;\n",
    "\"\"\").df()\n",
    "\n",
    "# Print the summaries\n",
    "print(summary)\n",
    "print(summary2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc5f11",
   "metadata": {},
   "source": [
    "## Pseudonomisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55ab2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique players from the final tracking table\n",
    "player = con.execute(\"\"\"\n",
    "SELECT DISTINCT player_id\n",
    "FROM tracking_player\n",
    "\"\"\").df()\n",
    "\n",
    "# Assign a sequential number to each player\n",
    "player['player_number'] = np.arange(1, len(player) + 1)\n",
    "\n",
    "# Save the mapping to a CSV file\n",
    "player.to_csv(\"data/player_numbering.txt\", index=False, header=True)\n",
    "\n",
    "# Register the numbered players as a temporary table in DuckDB\n",
    "con.register(\"player_numbered\", player)\n",
    "\n",
    "# Retrieve all column names from tracking_player except 'player_id'\n",
    "cols = con.execute(\"PRAGMA table_info(tracking_player)\").df()\n",
    "cols = [c for c in cols['name'] if c != 'player_id']\n",
    "cols_sql = \", \".join([f\"tp.{c}\" for c in cols])  # Prepare columns for SQL\n",
    "\n",
    "# Create a table with pseudo numbers instead of player_id\n",
    "con.execute(f\"\"\"\n",
    "CREATE OR REPLACE TABLE tracking_pseudo AS\n",
    "SELECT\n",
    "    {cols_sql},\n",
    "    pn.player_number AS player_pseudo  -- Use player_number as pseudo\n",
    "FROM tracking_player tp\n",
    "JOIN player_numbered pn ON tp.player_id = pn.player_id\n",
    "\"\"\")\n",
    "\n",
    "# Retrieve all distinct session dates for player pseudo 20 in year 2020\n",
    "df_sessions = con.execute(\"\"\"\n",
    "SELECT DISTINCT session_date\n",
    "FROM tracking_pseudo\n",
    "WHERE player_pseudo = 20\n",
    "  AND YEAR(session_date) = 2020\n",
    "ORDER BY session_date\n",
    "\"\"\").df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ce320",
   "metadata": {},
   "source": [
    "## Vitesse abérante\n",
    "Nettoyage des vitesse abérantes par 2 algorythme position par z-score et vitesse par IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d522ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions to analyze: 46\n",
      "[1/46] 1 | practice | 2019-09-18 00:00:00 | 10\n",
      "[2/46] 1 | practice | 2020-03-04 00:00:00 | 10\n",
      "[3/46] 5 | practice | 2019-09-14 00:00:00 | 14\n",
      "[4/46] 5 | practice | 2020-03-13 00:00:00 | 14\n",
      "[5/46] 6 | practice | 2019-07-08 00:00:00 | 7\n",
      "[6/46] 8 | practice | 2021-01-08 00:00:00 | 10\n",
      "[7/46] 10 | practice | 2020-01-24 00:00:00 | 12\n",
      "[8/46] 11 | practice | 2019-07-08 00:00:00 | 1\n",
      "[9/46] 11 | practice | 2020-03-13 00:00:00 | 20\n",
      "[10/46] 12 | practice | 2021-01-08 00:00:00 | 27\n",
      "[11/46] 13 | game | 2020-12-12 00:00:00 | 11\n",
      "[12/46] 13 | practice | 2020-02-06 00:00:00 | 11\n",
      "[13/46] 13 | practice | 2020-03-13 00:00:00 | 11\n",
      "[14/46] 19 | practice | 2019-07-11 00:00:00 | 3\n",
      "[15/46] 19 | practice | 2019-08-31 00:00:00 | 3\n",
      "[16/46] 19 | practice | 2020-02-04 00:00:00 | 3\n",
      "[17/46] 22 | practice | 2019-09-28 00:00:00 | 28\n",
      "[18/46] 23 | practice | 2020-11-04 00:00:00 | 14\n",
      "[19/46] 23 | practice | 2020-11-18 00:00:00 | 14\n",
      "[20/46] 25 | practice | 2020-03-13 00:00:00 | 13\n",
      "[21/46] 26 | practice | 2020-01-20 00:00:00 | 7\n",
      "[22/46] 26 | practice | 2020-09-16 00:00:00 | 7\n",
      "[23/46] 26 | practice | 2020-10-03 00:00:00 | 7\n",
      "[24/46] 27 | practice | 2020-03-13 00:00:00 | 15\n",
      "[25/46] 29 | practice | 2020-03-13 00:00:00 | 17\n",
      "[26/46] 29 | practice | 2021-01-08 00:00:00 | 17\n",
      "[27/46] 30 | practice | 2020-03-13 00:00:00 | 4\n",
      "[28/46] 30 | practice | 2020-11-04 00:00:00 | 4\n",
      "[29/46] 30 | practice | 2020-11-11 00:00:00 | 4\n",
      "[30/46] 30 | practice | 2021-01-08 00:00:00 | 4\n",
      "[31/46] 32 | practice | 2021-01-11 00:00:00 | 25\n",
      "[32/46] 33 | practice | 2020-03-13 00:00:00 | 3\n",
      "[33/46] 34 | practice | 2020-03-13 00:00:00 | 5\n",
      "[34/46] 34 | practice | 2020-11-04 00:00:00 | 5\n",
      "[35/46] 34 | practice | 2021-01-08 00:00:00 | 5\n",
      "[36/46] 35 | practice | 2019-11-02 00:00:00 | 77\n",
      "[37/46] 35 | practice | 2020-02-06 00:00:00 | 77\n",
      "[38/46] 35 | practice | 2020-03-13 00:00:00 | 77\n",
      "[39/46] 36 | practice | 2019-09-18 00:00:00 | 21\n",
      "[40/46] 37 | game | 2020-07-05 00:00:00 | 9\n",
      "[41/46] 37 | practice | 2019-08-29 00:00:00 | 9\n",
      "[42/46] 37 | practice | 2020-02-06 00:00:00 | 9\n",
      "[43/46] 37 | practice | 2020-03-13 00:00:00 | 9\n",
      "[44/46] 39 | practice | 2021-01-08 00:00:00 | 9\n",
      "[45/46] 40 | practice | 2020-03-13 00:00:00 | 2\n",
      "[46/46] 41 | practice | 2019-07-18 00:00:00 | 19\n",
      "Outlier detection completed\n",
      "Table 'outlier_sequences' created\n",
      "\n",
      "=== OUTLIER SEQUENCES SUMMARY BY SESSION ===\n",
      "    player_pseudo session_type session_date  sensor_id  nb_sequences  \\\n",
      "0              37         game   2020-07-05          9            19   \n",
      "1               5     practice   2020-03-13         14             5   \n",
      "2              13     practice   2020-02-06         11             5   \n",
      "3              37     practice   2020-03-13          9             4   \n",
      "4              26     practice   2020-10-03          7             4   \n",
      "5              11     practice   2019-07-08          1             4   \n",
      "6              27     practice   2020-03-13         15             4   \n",
      "7              25     practice   2020-03-13         13             3   \n",
      "8               6     practice   2019-07-08          7             3   \n",
      "9              36     practice   2019-09-18         21             3   \n",
      "10             13     practice   2020-03-13         11             2   \n",
      "11             30     practice   2020-03-13          4             2   \n",
      "12              8     practice   2021-01-08         10             2   \n",
      "13             29     practice   2020-03-13         17             2   \n",
      "14             30     practice   2021-01-08          4             2   \n",
      "15             35     practice   2020-03-13         77             2   \n",
      "16             37     practice   2019-08-29          9             2   \n",
      "17             33     practice   2020-03-13          3             2   \n",
      "18             11     practice   2020-03-13         20             2   \n",
      "19             35     practice   2019-11-02         77             2   \n",
      "20              1     practice   2019-09-18         10             2   \n",
      "21              1     practice   2020-03-04         10             2   \n",
      "22             19     practice   2019-07-11          3             2   \n",
      "23             19     practice   2020-02-04          3             2   \n",
      "24             23     practice   2020-11-18         14             2   \n",
      "25             29     practice   2021-01-08         17             2   \n",
      "26             34     practice   2020-03-13          5             2   \n",
      "27             34     practice   2021-01-08          5             2   \n",
      "28             37     practice   2020-02-06          9             2   \n",
      "29             39     practice   2021-01-08          9             2   \n",
      "30             40     practice   2020-03-13          2             2   \n",
      "31             35     practice   2020-02-06         77             2   \n",
      "32             22     practice   2019-09-28         28             1   \n",
      "33             32     practice   2021-01-11         25             1   \n",
      "34             34     practice   2020-11-04          5             1   \n",
      "35             12     practice   2021-01-08         27             1   \n",
      "36              5     practice   2019-09-14         14             1   \n",
      "37             26     practice   2020-01-20          7             1   \n",
      "38             13         game   2020-12-12         11             1   \n",
      "39             19     practice   2019-08-31          3             1   \n",
      "40             10     practice   2020-01-24         12             1   \n",
      "41             23     practice   2020-11-04         14             1   \n",
      "42             26     practice   2020-09-16          7             1   \n",
      "43             30     practice   2020-11-04          4             1   \n",
      "44             30     practice   2020-11-11          4             1   \n",
      "45             41     practice   2019-07-18         19             1   \n",
      "\n",
      "    total_outlier_points  \n",
      "0                 1711.0  \n",
      "1                  785.0  \n",
      "2                 1308.0  \n",
      "3                  831.0  \n",
      "4                  231.0  \n",
      "5                  588.0  \n",
      "6                  443.0  \n",
      "7                  508.0  \n",
      "8                  212.0  \n",
      "9                 1936.0  \n",
      "10                1574.0  \n",
      "11                 391.0  \n",
      "12                1704.0  \n",
      "13                1577.0  \n",
      "14                1690.0  \n",
      "15                1572.0  \n",
      "16                1590.0  \n",
      "17                1568.0  \n",
      "18                 329.0  \n",
      "19                 455.0  \n",
      "20                1788.0  \n",
      "21                3809.0  \n",
      "22                1101.0  \n",
      "23                3610.0  \n",
      "24                2065.0  \n",
      "25                1698.0  \n",
      "26                1565.0  \n",
      "27                1696.0  \n",
      "28                1521.0  \n",
      "29                1693.0  \n",
      "30                1570.0  \n",
      "31                1228.0  \n",
      "32                1466.0  \n",
      "33                2840.0  \n",
      "34                 830.0  \n",
      "35                1700.0  \n",
      "36                1105.0  \n",
      "37                2951.0  \n",
      "38                  56.0  \n",
      "39                1307.0  \n",
      "40                 294.0  \n",
      "41                 824.0  \n",
      "42                  22.0  \n",
      "43                 834.0  \n",
      "44                1875.0  \n",
      "45                1714.0  \n",
      "Number of sessions to correct: 46\n",
      "[1/46] 1 | practice | 2019-09-18 00:00:00 corrected\n",
      "[2/46] 1 | practice | 2020-03-04 00:00:00 corrected\n",
      "[3/46] 5 | practice | 2019-09-14 00:00:00 corrected\n",
      "[4/46] 5 | practice | 2020-03-13 00:00:00 corrected\n",
      "[5/46] 6 | practice | 2019-07-08 00:00:00 corrected\n",
      "[6/46] 8 | practice | 2021-01-08 00:00:00 corrected\n",
      "[7/46] 10 | practice | 2020-01-24 00:00:00 corrected\n",
      "[8/46] 11 | practice | 2019-07-08 00:00:00 corrected\n",
      "[9/46] 11 | practice | 2020-03-13 00:00:00 corrected\n",
      "[10/46] 12 | practice | 2021-01-08 00:00:00 corrected\n",
      "[11/46] 13 | game | 2020-12-12 00:00:00 corrected\n",
      "[12/46] 13 | practice | 2020-02-06 00:00:00 corrected\n",
      "[13/46] 13 | practice | 2020-03-13 00:00:00 corrected\n",
      "[14/46] 19 | practice | 2019-07-11 00:00:00 corrected\n",
      "[15/46] 19 | practice | 2019-08-31 00:00:00 corrected\n",
      "[16/46] 19 | practice | 2020-02-04 00:00:00 corrected\n",
      "[17/46] 22 | practice | 2019-09-28 00:00:00 corrected\n",
      "[18/46] 23 | practice | 2020-11-04 00:00:00 corrected\n",
      "[19/46] 23 | practice | 2020-11-18 00:00:00 corrected\n",
      "[20/46] 25 | practice | 2020-03-13 00:00:00 corrected\n",
      "[21/46] 26 | practice | 2020-01-20 00:00:00 corrected\n",
      "[22/46] 26 | practice | 2020-09-16 00:00:00 corrected\n",
      "[23/46] 26 | practice | 2020-10-03 00:00:00 corrected\n",
      "[24/46] 27 | practice | 2020-03-13 00:00:00 corrected\n",
      "[25/46] 29 | practice | 2020-03-13 00:00:00 corrected\n",
      "[26/46] 29 | practice | 2021-01-08 00:00:00 corrected\n",
      "[27/46] 30 | practice | 2020-03-13 00:00:00 corrected\n",
      "[28/46] 30 | practice | 2020-11-04 00:00:00 corrected\n",
      "[29/46] 30 | practice | 2020-11-11 00:00:00 corrected\n",
      "[30/46] 30 | practice | 2021-01-08 00:00:00 corrected\n",
      "[31/46] 32 | practice | 2021-01-11 00:00:00 corrected\n",
      "[32/46] 33 | practice | 2020-03-13 00:00:00 corrected\n",
      "[33/46] 34 | practice | 2020-03-13 00:00:00 corrected\n",
      "[34/46] 34 | practice | 2020-11-04 00:00:00 corrected\n",
      "[35/46] 34 | practice | 2021-01-08 00:00:00 corrected\n",
      "[36/46] 35 | practice | 2019-11-02 00:00:00 corrected\n",
      "[37/46] 35 | practice | 2020-02-06 00:00:00 corrected\n",
      "[38/46] 35 | practice | 2020-03-13 00:00:00 corrected\n",
      "[39/46] 36 | practice | 2019-09-18 00:00:00 corrected\n",
      "[40/46] 37 | game | 2020-07-05 00:00:00 corrected\n",
      "[41/46] 37 | practice | 2019-08-29 00:00:00 corrected\n",
      "[42/46] 37 | practice | 2020-02-06 00:00:00 corrected\n",
      "[43/46] 37 | practice | 2020-03-13 00:00:00 corrected\n",
      "[44/46] 39 | practice | 2021-01-08 00:00:00 corrected\n",
      "[45/46] 40 | practice | 2020-03-13 00:00:00 corrected\n",
      "[46/46] 41 | practice | 2019-07-18 00:00:00 corrected\n",
      "\n",
      "All sessions corrected and stored in 'tracking_corrected'\n",
      "Table 'tracking_clean' created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================ \n",
    "# STEP 1: DETECT OUTLIERS BASED ON EXCESSIVE SPEED\n",
    "# ============================================================================\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW extreme_vitesse AS\n",
    "SELECT\n",
    "    player_pseudo,\n",
    "    session_type,\n",
    "    session_date,\n",
    "    sensor_id,\n",
    "    MAX(speed_kmh) AS max_speed\n",
    "FROM tracking_pseudo\n",
    "GROUP BY player_pseudo, session_type, session_date, sensor_id\n",
    "HAVING MAX(speed_kmh) > 35;  -- Keep only sessions where max speed exceeds 35 km/h\n",
    "\"\"\").df()\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# STEP 2: IDENTIFY EXACT POINTS WITH OUTLIERS\n",
    "# ============================================================================\n",
    "\n",
    "def detect_outlier_sequences_position_z(df, z_threshold=3):\n",
    "    \"\"\"\n",
    "    Detect positional outliers based on z-score of x and y coordinates.\n",
    "    Marks start and end of continuous outlier sequences.\n",
    "    \"\"\"\n",
    "    df = df.sort_values('time_utc').reset_index(drop=True)\n",
    "    \n",
    "    mean_x = df['x_pos'].mean()\n",
    "    std_x = df['x_pos'].std()\n",
    "    mean_y = df['y_pos'].mean()\n",
    "    std_y = df['y_pos'].std()\n",
    "    \n",
    "    df['z_x'] = (df['x_pos'] - mean_x) / std_x\n",
    "    df['z_y'] = (df['y_pos'] - mean_y) / std_y\n",
    "    df['z_dist'] = np.sqrt(df['z_x']**2 + df['z_y']**2)\n",
    "    \n",
    "    df['is_outlier_position'] = df['z_dist'] > z_threshold\n",
    "    \n",
    "    # Initialize start/end flags for sequences\n",
    "    df['outlier_start_position'] = False\n",
    "    df['outlier_end_position'] = False\n",
    "    \n",
    "    # Mark start and end of consecutive outlier sequences\n",
    "    in_sequence = False\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, 'is_outlier_position'] and not in_sequence:\n",
    "            df.loc[i, 'outlier_start_position'] = True\n",
    "            in_sequence = True\n",
    "        elif not df.loc[i, 'is_outlier_position'] and in_sequence:\n",
    "            df.loc[i-1, 'outlier_end_position'] = True\n",
    "            in_sequence = False\n",
    "    if in_sequence:\n",
    "        df.loc[len(df)-1, 'outlier_end_position'] = True\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def detect_local_outliers_speed_iqr_global_iqr(df, speed_trigger=35, window_sec=5, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Detect speed outliers using IQR method within a window around peaks exceeding speed_trigger.\n",
    "    Marks start and end of continuous speed outlier sequences.\n",
    "    \"\"\"\n",
    "    df = df.sort_values('time_utc').reset_index(drop=True)\n",
    "    df['is_outlier_speed'] = False\n",
    "\n",
    "    # Compute global IQR thresholds\n",
    "    Q1_global = df['speed_kmh'].quantile(0.25)\n",
    "    Q3_global = df['speed_kmh'].quantile(0.75)\n",
    "    IQR_global = Q3_global - Q1_global\n",
    "    lower_global = Q1_global - multiplier * IQR_global\n",
    "    upper_global = Q3_global + multiplier * IQR_global\n",
    "\n",
    "    # Identify high-speed peaks\n",
    "    peaks = df[df['speed_kmh'] > speed_trigger]['time_utc']\n",
    "\n",
    "    # Flag outliers around each peak in a time window\n",
    "    for peak_time in peaks:\n",
    "        start_time = peak_time - pd.Timedelta(seconds=window_sec)\n",
    "        end_time = peak_time + pd.Timedelta(seconds=window_sec)\n",
    "\n",
    "        mask = (\n",
    "            (df['time_utc'] >= start_time) &\n",
    "            (df['time_utc'] <= end_time) &\n",
    "            ((df['speed_kmh'] < lower_global) | (df['speed_kmh'] > upper_global))\n",
    "        )\n",
    "\n",
    "        df.loc[mask, 'is_outlier_speed'] = True\n",
    "\n",
    "    # Initialize start/end flags for sequences\n",
    "    df['outlier_start_speed'] = False\n",
    "    df['outlier_end_speed'] = False\n",
    "    \n",
    "    # Mark start and end of consecutive speed outlier sequences\n",
    "    in_sequence = False\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i, 'is_outlier_speed'] and not in_sequence:\n",
    "            df.loc[i, 'outlier_start_speed'] = True\n",
    "            in_sequence = True\n",
    "        elif not df.loc[i, 'is_outlier_speed'] and in_sequence:\n",
    "            df.loc[i-1, 'outlier_end_speed'] = True\n",
    "            in_sequence = False\n",
    "    if in_sequence:\n",
    "        df.loc[len(df)-1, 'outlier_end_speed'] = True\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# RETRIEVE SESSIONS TO ANALYZE\n",
    "# ============================================================================\n",
    "\n",
    "sessions_to_analyze = con.execute(\"\"\"\n",
    "SELECT DISTINCT \n",
    "    player_pseudo,\n",
    "    session_type,\n",
    "    session_date,\n",
    "    sensor_id\n",
    "FROM extreme_vitesse\n",
    "ORDER BY player_pseudo, session_type, session_date, sensor_id\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"Sessions to analyze: {len(sessions_to_analyze)}\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# CREATE TABLE TO STORE OUTLIER POINTS\n",
    "# ============================================================================\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE outliers_points (\n",
    "    player_pseudo BIGINT,\n",
    "    session_type VARCHAR,\n",
    "    session_date DATE,\n",
    "    sensor_id INTEGER,\n",
    "    time_utc TIMESTAMP,\n",
    "    x_pos DOUBLE,\n",
    "    y_pos DOUBLE,\n",
    "    speed_kmh DOUBLE,\n",
    "    is_outlier_combined BOOLEAN,\n",
    "    outlier_start_combined BOOLEAN,\n",
    "    outlier_end_combined BOOLEAN\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# ANALYZE EACH SESSION\n",
    "# ============================================================================\n",
    "\n",
    "for idx, session in sessions_to_analyze.iterrows():\n",
    "    player = session['player_pseudo']\n",
    "    session_type = session['session_type']\n",
    "    date = session['session_date']\n",
    "    sensor = session['sensor_id']\n",
    "    \n",
    "    print(f\"[{idx+1}/{len(sessions_to_analyze)}] {player} | {session_type} | {date} | {sensor}\")\n",
    "    \n",
    "    # Retrieve session data\n",
    "    df_session = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        player_pseudo,\n",
    "        session_type,\n",
    "        session_date,\n",
    "        sensor_id,\n",
    "        time_utc,\n",
    "        x_pos,\n",
    "        y_pos,\n",
    "        speed_kmh\n",
    "    FROM tracking_pseudo\n",
    "    WHERE player_pseudo = '{player}'\n",
    "      AND session_type = '{session_type}'\n",
    "      AND session_date = '{date}'\n",
    "      AND sensor_id = '{sensor}'\n",
    "    ORDER BY time_utc\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # Detect position and speed outliers\n",
    "    df_with_outliers = detect_outlier_sequences_position_z(df_session)\n",
    "    df_with_outliers = detect_local_outliers_speed_iqr_global_iqr(df_with_outliers)\n",
    "\n",
    "    # Combine outlier flags\n",
    "    df_with_outliers['is_outlier_combined'] = (\n",
    "        df_with_outliers['is_outlier_position'] |\n",
    "        df_with_outliers['is_outlier_speed']\n",
    "    )\n",
    "\n",
    "    df_with_outliers['outlier_start_combined'] = (\n",
    "        df_with_outliers['outlier_start_position'] |\n",
    "        df_with_outliers['outlier_start_speed']\n",
    "    )\n",
    "\n",
    "    df_with_outliers['outlier_end_combined'] = (\n",
    "        df_with_outliers['outlier_end_position'] |\n",
    "        df_with_outliers['outlier_end_speed']\n",
    "    )\n",
    "\n",
    "    # Keep only relevant columns for storage\n",
    "    df_to_save = df_with_outliers[[\n",
    "        'player_pseudo',\n",
    "        'session_type',\n",
    "        'session_date',\n",
    "        'sensor_id',\n",
    "        'time_utc',\n",
    "        'x_pos',\n",
    "        'y_pos',\n",
    "        'speed_kmh',\n",
    "        'is_outlier_combined',\n",
    "        'outlier_start_combined',\n",
    "        'outlier_end_combined'\n",
    "    ]]\n",
    "    \n",
    "    # Insert session results into outliers_points table\n",
    "    con.register('temp_outliers', df_to_save)\n",
    "    con.execute(\"INSERT INTO outliers_points SELECT * FROM temp_outliers\")\n",
    "    con.unregister('temp_outliers')\n",
    "\n",
    "print(\"Outlier detection completed\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# STEP 3: IDENTIFY CONTINUOUS OUTLIER SEQUENCES\n",
    "# ============================================================================\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE outlier_sequences AS\n",
    "WITH numbered_outliers AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY player_pseudo, session_type, session_date, sensor_id\n",
    "            ORDER BY time_utc\n",
    "        ) as row_num,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY player_pseudo, session_type, session_date, sensor_id\n",
    "            ORDER BY time_utc\n",
    "        ) - ROW_NUMBER() OVER (\n",
    "            PARTITION BY player_pseudo, session_type, session_date, sensor_id, is_outlier_combined\n",
    "            ORDER BY time_utc\n",
    "        ) as sequence_group\n",
    "    FROM outliers_points\n",
    "),\n",
    "sequences AS (\n",
    "    SELECT \n",
    "        player_pseudo,\n",
    "        session_type,\n",
    "        session_date,\n",
    "        sensor_id,\n",
    "        is_outlier_combined,\n",
    "        sequence_group,\n",
    "        MIN(time_utc) as seq_start_time,\n",
    "        MAX(time_utc) as seq_end_time,\n",
    "        COUNT(*) as seq_length,\n",
    "        MIN(row_num) as start_row,\n",
    "        MAX(row_num) as end_row\n",
    "    FROM numbered_outliers\n",
    "    GROUP BY player_pseudo, session_type, session_date, sensor_id, is_outlier_combined, sequence_group\n",
    ")\n",
    "SELECT \n",
    "    player_pseudo,\n",
    "    session_type,\n",
    "    session_date,\n",
    "    sensor_id,\n",
    "    is_outlier_combined,\n",
    "    sequence_group,\n",
    "    seq_start_time,\n",
    "    seq_end_time,\n",
    "    seq_length,\n",
    "    EXTRACT(EPOCH FROM (seq_end_time - seq_start_time)) as duration_seconds,\n",
    "    start_row,\n",
    "    end_row\n",
    "FROM sequences\n",
    "WHERE is_outlier_combined = TRUE\n",
    "ORDER BY player_pseudo, session_type, session_date, sensor_id, seq_start_time\n",
    "\"\"\")\n",
    "\n",
    "print(\"Table 'outlier_sequences' created\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# FINAL SUMMARY OF SEQUENCES\n",
    "# ============================================================================\n",
    "\n",
    "sequences_summary = con.execute(\"\"\"\n",
    "SELECT \n",
    "    player_pseudo,\n",
    "    session_type,\n",
    "    session_date,\n",
    "    sensor_id,\n",
    "    COUNT(*) as nb_sequences,\n",
    "    SUM(seq_length) as total_outlier_points\n",
    "FROM outlier_sequences\n",
    "GROUP BY player_pseudo, session_type, session_date, sensor_id\n",
    "ORDER BY nb_sequences DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\n=== OUTLIER SEQUENCES SUMMARY BY SESSION ===\")\n",
    "print(sequences_summary)\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# STEP 4: CORRECT OUTLIERS BY IMPUTING MEAN VALUES (ALL PLAYERS)\n",
    "# ============================================================================\n",
    "\n",
    "sessions_to_correct = con.execute(\"\"\"\n",
    "SELECT DISTINCT \n",
    "    player_pseudo, \n",
    "    session_type,\n",
    "    session_date, \n",
    "    sensor_id\n",
    "FROM outliers_points\n",
    "ORDER BY player_pseudo, session_type, session_date, sensor_id\n",
    "\"\"\").df()\n",
    "\n",
    "print(f\"Number of sessions to correct: {len(sessions_to_correct)}\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# CREATE TABLE TO STORE CORRECTED TRACKING\n",
    "# ============================================================================\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE tracking_corrected (\n",
    "    player_pseudo BIGINT,\n",
    "    session_type VARCHAR,\n",
    "    session_date DATE,\n",
    "    sensor_id INTEGER,\n",
    "    time_utc TIMESTAMP,\n",
    "    x_pos DOUBLE,\n",
    "    y_pos DOUBLE,\n",
    "    speed_kmh DOUBLE\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# LOOP OVER EACH SESSION TO APPLY CORRECTION\n",
    "# ============================================================================\n",
    "\n",
    "for idx, session in sessions_to_correct.iterrows():\n",
    "    player = session['player_pseudo']\n",
    "    session_type = session['session_type']\n",
    "    date = session['session_date']\n",
    "    sensor = session['sensor_id']\n",
    "    \n",
    "    # Retrieve session data with outlier flags\n",
    "    df_session = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        t.player_pseudo, \n",
    "        t.session_type,\n",
    "        t.session_date, \n",
    "        t.sensor_id, \n",
    "        t.time_utc,\n",
    "        t.x_pos, \n",
    "        t.y_pos, \n",
    "        t.speed_kmh,\n",
    "        o.is_outlier_combined\n",
    "    FROM tracking_pseudo t\n",
    "    LEFT JOIN outliers_points o\n",
    "      ON t.player_pseudo = o.player_pseudo\n",
    "      AND t.session_type = o.session_type\n",
    "      AND t.session_date = o.session_date\n",
    "      AND t.sensor_id = o.sensor_id\n",
    "      AND t.time_utc = o.time_utc\n",
    "    WHERE t.player_pseudo = '{player}'\n",
    "      AND t.session_type = '{session_type}'\n",
    "      AND t.session_date = '{date}'\n",
    "      AND t.sensor_id = '{sensor}'\n",
    "    ORDER BY t.time_utc\n",
    "    \"\"\").df()\n",
    "    \n",
    "    # Replace NULL flags with False\n",
    "    df_session['is_outlier_combined'] = df_session['is_outlier_combined'].fillna(False)\n",
    "\n",
    "    # Compute mean values from valid points\n",
    "    valid_points = df_session[~df_session['is_outlier_combined']]\n",
    "    mean_speed = valid_points['speed_kmh'].mean()\n",
    "    mean_x = valid_points['x_pos'].mean()\n",
    "    mean_y = valid_points['y_pos'].mean()\n",
    "    \n",
    "    # Impute mean values for outliers\n",
    "    df_session.loc[df_session['is_outlier_combined'], 'speed_kmh'] = mean_speed\n",
    "    df_session.loc[df_session['is_outlier_combined'], 'x_pos'] = mean_x\n",
    "    df_session.loc[df_session['is_outlier_combined'], 'y_pos'] = mean_y\n",
    "    \n",
    "    # Drop temporary column before saving\n",
    "    df_to_save = df_session.drop(columns=['is_outlier_combined'])\n",
    "    \n",
    "    # Insert corrected session into table\n",
    "    con.register('temp_corrected', df_to_save)\n",
    "    con.execute(\"\"\"\n",
    "    INSERT INTO tracking_corrected \n",
    "    SELECT * FROM temp_corrected\n",
    "    \"\"\")\n",
    "    con.unregister('temp_corrected')\n",
    "    \n",
    "    print(f\"[{idx+1}/{len(sessions_to_correct)}] {player} | {session_type} | {date} corrected\")\n",
    "\n",
    "print(\"\\nAll sessions corrected and stored in 'tracking_corrected'\")\n",
    "\n",
    "\n",
    "# ============================================================================ \n",
    "# STEP 5: CREATE FINAL CLEANED TABLE\n",
    "# ============================================================================\n",
    "\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE tracking_clean AS\n",
    "\n",
    "-- 1) Include corrected sessions\n",
    "SELECT *\n",
    "FROM tracking_corrected\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- 2) Include sessions without outliers\n",
    "SELECT \n",
    "    t.player_pseudo,\n",
    "    t.session_type,\n",
    "    t.session_date,\n",
    "    t.sensor_id,\n",
    "    t.time_utc,\n",
    "    t.x_pos,\n",
    "    t.y_pos,\n",
    "    t.speed_kmh\n",
    "FROM tracking_pseudo t\n",
    "\n",
    "LEFT JOIN outliers_points o\n",
    "  ON t.player_pseudo = o.player_pseudo\n",
    " AND t.session_type = o.session_type\n",
    " AND t.session_date = o.session_date\n",
    " AND t.sensor_id = o.sensor_id\n",
    " AND t.time_utc = o.time_utc\n",
    "\n",
    "WHERE o.player_pseudo IS NULL\n",
    "\"\"\")\n",
    "\n",
    "print(\"Table 'tracking_clean' created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19970c1",
   "metadata": {},
   "source": [
    "## Individuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e1bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Paramètres\n",
    "# ===============================\n",
    "month = '2020-03'          # Format YYYY-MM pour le mois ciblé\n",
    "session_type = 'game'\n",
    "fs = 10                    # Hz\n",
    "dt = 1 / fs\n",
    "player_selected = 6      # mettre le pseudo du joueur pour filtrer, sinon None pour tous\n",
    "table_name = f\"game_metrics_{month.replace('-', '_')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd602a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'game_metrics_2020_03' créée/replacée avec succès !\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================ \n",
    "# Speed zones function\n",
    "# ============================================================================\n",
    "\n",
    "def speed_zone(player, month):\n",
    "    # Récupérer la vitesse max du joueur sur le mois\n",
    "    df_speed = con.execute(f\"\"\"\n",
    "    SELECT\n",
    "        strftime('%Y-%m', session_date) AS month,\n",
    "        player_pseudo,\n",
    "        MAX(speed_kmh) AS max_speed_kmh\n",
    "    FROM tracking_games\n",
    "    WHERE player_pseudo = '{player}'\n",
    "    AND strftime('%Y-%m', session_date) = '{month}'\n",
    "    GROUP BY month, player_pseudo\n",
    "    \"\"\").df()\n",
    "    \n",
    "    if df_speed.empty:\n",
    "        raise ValueError(f\"Aucune donnée pour le joueur {player} sur le mois {month}\")\n",
    "    \n",
    "    vmax = df_speed['max_speed_kmh'].values[0]\n",
    "\n",
    "    # Définition des zones\n",
    "    zones = [0,0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    labels = [\n",
    "        '0-40%',\n",
    "        '40-50%',\n",
    "        '50-60%',\n",
    "        '60-70%',\n",
    "        '70-80%',\n",
    "        '80-90%',\n",
    "        '90-100%'\n",
    "    ]\n",
    "\n",
    "    df_zone = pd.DataFrame({\n",
    "        'zone': labels,\n",
    "        'min_speed_kmh': [vmax * z1 for z1 in zones[:-1]],\n",
    "        'max_speed_kmh': [vmax * z2 for z2 in zones[1:]],\n",
    "    })\n",
    "    return df_zone\n",
    "\n",
    "# ============================================================================ \n",
    "# Acceleration_velocity profile function\n",
    "# ============================================================================\n",
    "\n",
    "def acceleration_profile(player=None, month='2020-03', fs=10, dt=None, v_start=0, step=0.72, v_threshold=10.8, fig=None, ax=None, show_plot=True):\n",
    "    \"\"\"\n",
    "    Calcule et trace le profil accélération-vitesse pour tous les matchs du mois.\n",
    "    fig, ax : matplotlib figure/axes à utiliser (None pour créer une nouvelle figure)\n",
    "    show_plot : bool, si True fait plt.show()\n",
    "    \"\"\"\n",
    "    dt = dt or 1 / fs\n",
    "\n",
    "    # Récupération des données\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM tracking_games\n",
    "    WHERE strftime('%Y-%m', session_date) = '{month}'\n",
    "    \"\"\"\n",
    "    if player is not None:\n",
    "        query += f\" AND player_pseudo = {player}\"\n",
    "\n",
    "    query += \" ORDER BY player_pseudo, session_date, time_utc\"\n",
    "\n",
    "    df = con.execute(query).df()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"Aucune donnée pour le joueur {player} sur le mois {month}\")\n",
    "\n",
    "    # Calcul vitesse m/s et accélération\n",
    "    df['speed_ms'] = df['speed_kmh'] / 3.6\n",
    "    df['acceleration'] = df['speed_ms'].diff() / dt\n",
    "\n",
    "    # Filtrage des vitesses >= v_start\n",
    "    df = df[df['speed_kmh'] >= v_start].copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Pas de vitesses supérieures ou égales à v_start\")\n",
    "\n",
    "    # Création des bins\n",
    "    v_max = df['speed_kmh'].max()\n",
    "    bins = np.arange(v_start, v_max + step, step) if v_max > v_start else np.array([v_start, v_start + step])\n",
    "    df['speed_bin'] = pd.cut(df['speed_kmh'], bins=bins, include_lowest=True)\n",
    "\n",
    "    # Sélection des accélérations max par bin\n",
    "    df_max_acc = (\n",
    "        df.sort_values('acceleration', ascending=False)\n",
    "          .groupby('speed_bin')\n",
    "          .head(2)\n",
    "          .dropna(subset=['speed_bin'])\n",
    "    )\n",
    "\n",
    "    # Filtrage pour la régression\n",
    "    df_reg = df_max_acc[df_max_acc['speed_kmh'] >= v_threshold].copy()\n",
    "    df_reg = df_reg.dropna(subset=['speed_kmh', 'acceleration'])\n",
    "    if df_reg.empty:\n",
    "        raise ValueError(\"Aucun point disponible pour la régression (> v_threshold)\")\n",
    "\n",
    "    # Régression linéaire\n",
    "    coef = np.polyfit(df_reg['speed_kmh'], df_reg['acceleration'], 1)\n",
    "    a, b = coef\n",
    "    v_line = np.linspace(df_reg['speed_kmh'].min(), df_reg['speed_kmh'].max(), 100)\n",
    "    acc_line = a * v_line + b\n",
    "\n",
    "    # Tracé\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    ax.scatter(df['speed_kmh'], df['acceleration'], alpha=0.2, color='black', label='Toutes les données')\n",
    "    ax.scatter(df_max_acc['speed_kmh'], df_max_acc['acceleration'], marker='x', color='red', label='Accélérations max par bin')\n",
    "    ax.axvline(x=v_threshold, color='blue', linestyle='--', label=f'{v_threshold} km/h')\n",
    "    ax.fill_betweenx(y=[df['acceleration'].min(), df['acceleration'].max()],\n",
    "                     x1=-1, x2=v_threshold, color='gray', alpha=0.3)\n",
    "    ax.plot(v_line, acc_line, linestyle='-', linewidth=2,\n",
    "            label=f\"Régression > {v_threshold} km/h\\nacc = {a:.3f}·v + {b:.3f}\")\n",
    "    ax.scatter(df_reg['speed_kmh'], df_reg['acceleration'], marker='o', color='green', label='Points pour régression')\n",
    "\n",
    "    ax.set_xlabel('Vitesse (km/h)')\n",
    "    ax.set_ylabel('Accélération (m/s²)')\n",
    "    ax.set_xlim(0)\n",
    "    ax.set_ylim(0)\n",
    "    title_player = f\"du joueur {player}\" if player else \"de tous les joueurs\"\n",
    "    ax.set_title(f'Profil accélération-vitesse {title_player} pour {month}')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# METRICS CALCULATION\n",
    "# ============================================================================\n",
    "df_match = con.execute(f\"\"\"\n",
    "SELECT\n",
    "    t.player_pseudo,\n",
    "    t.sensor_id,\n",
    "    s.position,\n",
    "    t.session_date\n",
    "FROM tracking_games t\n",
    "INNER JOIN summary s\n",
    "    ON t.sensor_id = s.Sensor\n",
    "    AND DATE(s.date) = t.session_date\n",
    "WHERE CAST(t.session_date AS VARCHAR) LIKE '{month}-%'\n",
    "AND t.session_type = '{session_type}'\n",
    "GROUP BY t.player_pseudo, t.sensor_id, s.position, t.session_date\n",
    "ORDER BY t.player_pseudo, t.session_date\n",
    "\"\"\").df()\n",
    "\n",
    "if df_match.empty:\n",
    "    raise ValueError(f\"Aucun match trouvé pour le mois {month}\")\n",
    "\n",
    "# Filtrer sur un joueur si demandé\n",
    "if player_selected is not None:\n",
    "    df_match = df_match[df_match['player_pseudo'] == player_selected]\n",
    "    if df_match.empty:\n",
    "        raise ValueError(f\"Aucun match pour le joueur {player_selected} ce mois-ci\")\n",
    "\n",
    "# ===============================\n",
    "# Fonction de calcul des metrics\n",
    "# ===============================\n",
    "def compute_metrics(df_player):\n",
    "    df_player = df_player.sort_values('time_utc')\n",
    "    \n",
    "    # Distance totale\n",
    "    df_player['dist'] = np.sqrt(df_player['x_pos'].diff()**2 + df_player['y_pos'].diff()**2)\n",
    "    max_distance = float(df_player['dist'].sum())\n",
    "    \n",
    "    # Accélération\n",
    "    df_player['speed_ms'] = df_player['speed_kmh'] / 3.6\n",
    "    df_player['acceleration'] = df_player['speed_ms'].diff() / dt\n",
    "    \n",
    "    # ===============================\n",
    "    # Pics d'accélération et décélération\n",
    "    # ===============================\n",
    "    acc_values = df_player['acceleration'].fillna(0).values\n",
    "    acc_peaks, _ = find_peaks(acc_values)\n",
    "    dcc_peaks_all, _ = find_peaks(-acc_values)\n",
    "    dcc_mask = acc_values[dcc_peaks_all] > -7.5\n",
    "    dcc_peaks = dcc_peaks_all[dcc_mask]\n",
    "    dcc_values = acc_values[dcc_peaks]\n",
    "\n",
    "    Nb_acc_2_5 = int(np.sum(acc_values[acc_peaks] > 2.5))\n",
    "    Nb_acc_3_5 = int(np.sum(acc_values[acc_peaks] > 3.5))\n",
    "    Nb_dcc_2_5 = int(np.sum(dcc_values < -2.5))\n",
    "    Nb_dcc_3_5 = int(np.sum(dcc_values < -3.5))\n",
    "    max_decceleration = float(dcc_values.min()) if len(dcc_values) > 0 else None\n",
    "    \n",
    "    # ===============================\n",
    "    # Changement de direction > 30°\n",
    "    # ===============================\n",
    "    dx = df_player['x_pos'].diff().values\n",
    "    dy = df_player['y_pos'].diff().values\n",
    "    vectors = np.column_stack((dx[1:], dy[1:]))\n",
    "    angles = []\n",
    "    for i in range(len(vectors)-1):\n",
    "        v1, v2 = vectors[i], vectors[i+1]\n",
    "        norm1, norm2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            angles.append(0)\n",
    "            continue\n",
    "        cos_theta = np.dot(v1, v2) / (norm1 * norm2)\n",
    "        cos_theta = np.clip(cos_theta, -1, 1)\n",
    "        theta = np.arccos(cos_theta) * 180 / np.pi\n",
    "        angles.append(theta)\n",
    "    angles = np.array(angles)\n",
    "    Nb_direction_changes = int(np.sum(angles > 30))\n",
    "    \n",
    "    # ===============================\n",
    "    # Time played\n",
    "    # ===============================\n",
    "    time_played = df_player['time_utc'].max() - df_player['time_utc'].min()\n",
    "    time_played_seconds = time_played.total_seconds()\n",
    "    hours = int(time_played_seconds // 3600)\n",
    "    minutes = int((time_played_seconds % 3600) // 60)\n",
    "    seconds = int(time_played_seconds % 60)\n",
    "    time_played_hms = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "    # ===============================\n",
    "    # Time in Speed zone (en %)\n",
    "    # ===============================\n",
    "    # Création des zones de vitesse pour ce joueur\n",
    "    vmax = df_player['speed_kmh'].max()\n",
    "    zones = [0, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    labels = ['0-40%', '40-50%', '50-60%', '60-70%', '70-80%', '80-90%', '90-100%']\n",
    "\n",
    "    df_player['speed_zone'] = pd.cut(\n",
    "        df_player['speed_kmh'],\n",
    "        bins=[vmax * z for z in zones],\n",
    "        labels=labels,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    # Compter le nombre de frames dans chaque zone et convertir en %\n",
    "    zone_counts = df_player['speed_zone'].value_counts(normalize=True) * 100\n",
    "\n",
    "    # ===============================\n",
    "    # Training Load normalisé\n",
    "    # ===============================\n",
    "    zone_coeffs = {\n",
    "        '0-40%': 1,\n",
    "        '40-50%': 2,\n",
    "        '50-60%': 3,\n",
    "        '60-70%': 4,\n",
    "        '70-80%': 5,\n",
    "        '80-90%': 6,\n",
    "        '90-100%': 7\n",
    "    }\n",
    "\n",
    "    training_load = sum(zone_counts.get(label, 0) * zone_coeffs[label] for label in labels)\n",
    "    training_load_normalized = training_load / 100  # normalisation sur 100%\n",
    "\n",
    "    # ===============================\n",
    "    # Metrics principales avec zones\n",
    "    # ===============================\n",
    "    metrics = {\n",
    "        'max_speed': float(df_player['speed_kmh'].max()) if not df_player['speed_kmh'].empty else None,\n",
    "        'max_distance': max_distance,\n",
    "        'max_acceleration': float(df_player['acceleration'].max()),\n",
    "        'max_decceleration': max_decceleration,\n",
    "        'max_direction_changes': Nb_direction_changes,\n",
    "        'Nb_acc_2_5': Nb_acc_2_5,\n",
    "        'Nb_acc_3_5': Nb_acc_3_5,\n",
    "        'Nb_dcc_2_5': Nb_dcc_2_5,\n",
    "        'Nb_dcc_3_5': Nb_dcc_3_5,\n",
    "        'time_played_hms': time_played_hms,\n",
    "        'training_load': round(training_load_normalized, 2)  # Ajout directement ici\n",
    "    }\n",
    "\n",
    "    # Ajouter les pourcentages de temps par zone\n",
    "    for label in labels:\n",
    "        metrics[f'time_in_zone_{label}'] = round(zone_counts.get(label, 0), 2)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ===============================\n",
    "# Calculer metrics pour chaque joueur et chaque match\n",
    "# ===============================\n",
    "metrics_rows = []\n",
    "for idx, row in df_match.iterrows():\n",
    "    player = row['player_pseudo']\n",
    "    session_date = row['session_date']\n",
    "    \n",
    "    df_player = con.execute(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM tracking_games\n",
    "        WHERE session_date = '{session_date}'\n",
    "        AND session_type = '{session_type}'\n",
    "        AND player_pseudo = {player}\n",
    "    \"\"\").df()\n",
    "    \n",
    "    metrics = compute_metrics(df_player)\n",
    "    metrics['player_pseudo'] = player\n",
    "    metrics['session_date'] = session_date\n",
    "    metrics_rows.append(metrics)\n",
    "\n",
    "# ===============================\n",
    "# Convertir en DataFrame et créer la table\n",
    "# ===============================\n",
    "df_metrics = pd.DataFrame(metrics_rows)\n",
    "table_name = f\"{session_type}_metrics_{month.replace('-', '_')}\"\n",
    "con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM df_metrics\")\n",
    "print(f\"Table '{table_name}' créée/replacée avec succès !\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# RADAR\n",
    "# ============================================================================\n",
    "\n",
    "radar_axes = [\n",
    "    'max_speed',\n",
    "    'max_acceleration',\n",
    "    'max_decceleration',\n",
    "    'Nb_acc_2_5',\n",
    "    'max_direction_changes'\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# Récupération données\n",
    "# ===============================\n",
    "df_metrics = con.execute(f\"SELECT * FROM {table_name}\").df()\n",
    "\n",
    "# ===============================\n",
    "# Récupération positions\n",
    "# ===============================\n",
    "df_positions = con.execute(f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    tg.player_pseudo,\n",
    "    s.position\n",
    "FROM tracking_games tg\n",
    "LEFT JOIN summary s\n",
    "    ON tg.sensor_id = s.Sensor\n",
    "   AND DATE(tg.session_date) = DATE(s.date)\n",
    "WHERE strftime('%Y-%m', tg.session_date) = '{month}'\n",
    "\"\"\").df()\n",
    "\n",
    "df_metrics = df_metrics.merge(df_positions, on='player_pseudo', how='left')\n",
    "\n",
    "# ===============================\n",
    "# Filtrer joueur si besoin\n",
    "# ===============================\n",
    "if player_selected is not None:\n",
    "    players = [player_selected] if isinstance(player_selected, int) else list(player_selected)\n",
    "    df_metrics = df_metrics[df_metrics['player_pseudo'].isin(players)]\n",
    "    if df_metrics.empty:\n",
    "        raise ValueError(f\"Aucun match pour le joueur {player_selected}\")\n",
    "\n",
    "# ===============================\n",
    "# Fonction normalisation\n",
    "# ===============================\n",
    "def normalize_df(df_source):\n",
    "\n",
    "    df_norm = df_source.copy()\n",
    "\n",
    "    for col in radar_axes:\n",
    "        if col == 'max_decceleration':\n",
    "            max_val = df_source[col].abs().max()\n",
    "            df_norm[col] = df_source[col].abs() / max_val * 100 if max_val > 0 else 0\n",
    "        else:\n",
    "            max_val = df_source[col].max()\n",
    "            df_norm[col] = df_source[col] / max_val * 100 if max_val > 0 else 0\n",
    "\n",
    "    return df_norm\n",
    "\n",
    "# ===============================\n",
    "# Fonction radar\n",
    "# ===============================\n",
    "def plot_radar(player, df_norm, title_suffix, ax=None, show_plot=True):\n",
    "    categories = radar_axes\n",
    "    N = len(categories)\n",
    "\n",
    "    values = df_norm[df_norm['player_pseudo'] == player][categories].mean().tolist()\n",
    "    values += values[:1]\n",
    "\n",
    "    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(polar=True))\n",
    "\n",
    "    ax.set_theta_offset(np.pi/2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, fontsize=11)\n",
    "\n",
    "    ax.set_yticks([20,40,60,80,100])\n",
    "    ax.set_ylim(0,100)\n",
    "\n",
    "    ax.spines['polar'].set_visible(False)\n",
    "\n",
    "    ax.plot(angles, values, linewidth=2, label=f'Joueur {player}')\n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    ax.set_title(f'Profil Radar {player} - {title_suffix} ({month})')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6492260",
   "metadata": {},
   "source": [
    "### Création PDF Stats Individuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "259cda30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF généré : Stats_Indiv_2020-03_player_6.pdf\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PDF GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "# ===============================\n",
    "# Fonction pour découper la table Metrics\n",
    "# ===============================\n",
    "def add_table_split(elements, df, n_splits=4):\n",
    "    \"\"\"\n",
    "    Découpe le DataFrame df en n_splits parties pour l'afficher complètement dans le PDF.\n",
    "    \"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    n_cols = len(cols)\n",
    "    # Nombre de colonnes par sous-table\n",
    "    cols_per_table = int(np.ceil(n_cols / n_splits))\n",
    "\n",
    "    for i in range(0, n_cols, cols_per_table):\n",
    "        sub_cols = cols[i:i+cols_per_table]\n",
    "        table_data = [sub_cols] + df[sub_cols].values.tolist()\n",
    "        t = Table(table_data)\n",
    "        t.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),\n",
    "            ('GRID', (0,0), (-1,-1), 1, colors.black)\n",
    "        ]))\n",
    "        elements.append(t)\n",
    "        elements.append(Spacer(1, 12))\n",
    "# ===============================\n",
    "# Boucle sur chaque joueur\n",
    "# ===============================\n",
    "for player in players_to_plot:\n",
    "\n",
    "    # Nom du PDF avec pseudo du joueur\n",
    "    pdf_filename = f\"Stats_Indiv_{month}_player_{player}.pdf\"\n",
    "\n",
    "    # Supprimer le fichier s'il existe déjà\n",
    "    if os.path.exists(pdf_filename):\n",
    "        os.remove(pdf_filename)\n",
    "\n",
    "    doc = SimpleDocTemplate(pdf_filename)\n",
    "    elements = []\n",
    "\n",
    "    style = styles.getSampleStyleSheet()\n",
    "    title_style = style[\"Heading1\"]\n",
    "    section_style = style[\"Heading2\"]\n",
    "\n",
    "    # ---------- Infos joueur ----------\n",
    "    elements.append(Paragraph(\"Stats individuel\", title_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    elements.append(Paragraph(f\"Joueur : {player}\", style[\"Normal\"]))\n",
    "    elements.append(Paragraph(f\"Date : {month}\", style[\"Normal\"]))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # ---------- SPEED ZONE ----------\n",
    "    elements.append(Paragraph(\"Speed Zone\", section_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    df_zone = speed_zone(player, month)\n",
    "    table_data = [df_zone.columns.tolist()] + df_zone.values.tolist()\n",
    "    table = Table(table_data)\n",
    "    table.setStyle(TableStyle([\n",
    "        ('BACKGROUND', (0,0), (-1,0), colors.grey),\n",
    "        ('GRID', (0,0), (-1,-1), 1, colors.black)\n",
    "    ]))\n",
    "    elements.append(table)\n",
    "    elements.append(Spacer(1, 20))\n",
    "\n",
    "    # ---------- ACCELERATION PROFILE ----------\n",
    "    elements.append(Paragraph(\"Acceleration-Velocity Profile\", section_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    acc_plot_path = f\"acc_profile_{player}.png\"\n",
    "    # Créer figure et passer ax pour tracer dedans\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    acceleration_profile(player, month, ax=ax, show_plot=False)\n",
    "    fig.savefig(acc_plot_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    elements.append(Image(acc_plot_path, width=5*inch, height=4*inch))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # ---------- METRICS ----------\n",
    "    elements.append(Paragraph(\"Metrics\", section_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    df_player_metrics = df_metrics[df_metrics['player_pseudo'] == player]\n",
    "    add_table_split(elements, df_player_metrics, n_splits=5)\n",
    "\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # ---------- RADAR 1 : Vs Tous ----------\n",
    "    elements.append(Paragraph(\"Radar - Vs Tous\", section_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    df_norm_all = normalize_df(df_metrics)\n",
    "    radar1_path = f\"radar_all_{player}.png\"\n",
    "    fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(polar=True))\n",
    "    plot_radar(player, df_norm_all, f\"Vs Tous les joueurs\", ax=ax, show_plot=False)\n",
    "    fig.savefig(radar1_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    elements.append(Image(radar1_path, width=4*inch, height=4*inch))\n",
    "    elements.append(Spacer(1, 20))\n",
    "\n",
    "    # ---------- RADAR 2 : Vs Poste ----------\n",
    "    elements.append(Paragraph(\"Radar - Vs Poste\", section_style))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    poste = df_metrics[df_metrics['player_pseudo'] == player]['position'].values[0]\n",
    "    df_poste = df_metrics[df_metrics['position'] == poste]\n",
    "    df_norm_poste = normalize_df(df_poste)\n",
    "    radar2_path = f\"radar_poste_{player}.png\"\n",
    "    fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(polar=True))\n",
    "    plot_radar(player, df_norm_poste, f\"Vs Poste {poste}\", ax=ax, show_plot=False)\n",
    "    fig.savefig(radar2_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    elements.append(Image(radar2_path, width=4*inch, height=4*inch))\n",
    "\n",
    "    # ---------- Build PDF ----------\n",
    "    doc.build(elements)\n",
    "    print(f\"PDF généré : {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aaedc5",
   "metadata": {},
   "source": [
    "# Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24eebc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
